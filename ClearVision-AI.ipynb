{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0kFpaXkiUYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD2ZJ7Uq6Od-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUJwX0s-pVKa",
        "outputId": "a6b3059a-98ea-469a-88f7-35c5c1de6f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Using port: 33659\n",
            "âœ… Model loaded successfully from: /content/drive/MyDrive/cataract_model/cataract_full_model_stage2.keras\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:33659\n",
            " * Running on http://172.28.0.12:33659\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ ngrok public URL: https://00e6b56e9ad0.ngrok-free.app\n",
            "Open it in browser to use the AI web interface.\n"
          ]
        }
      ],
      "source": [
        "# --- Run this whole cell in Colab ---\n",
        "\n",
        "# ============================\n",
        "# Install packages\n",
        "# ============================\n",
        "!pip install pyngrok flask_cors tensorflow pillow --quiet\n",
        "\n",
        "# ============================\n",
        "# Imports\n",
        "# ============================\n",
        "from pyngrok import ngrok\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "from flask_cors import CORS\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import threading, io, base64, os, numpy as np, time\n",
        "import tensorflow as tf\n",
        "from keras import config as keras_config  # for unsafe deserialization\n",
        "\n",
        "# ============================\n",
        "# CONFIG\n",
        "# ============================\n",
        "MODEL_PATH = \"/content/cataract_full_model_stage2.keras\"\n",
        "LABELS = [\"Normal Eye\", \"Cataract Eye\"]\n",
        "DEFAULT_PORT = 5000\n",
        "NGROK_AUTHTOKEN = \"YOUR_NGROK_AUTHTOKEN\"  # <--- paste your own token here\n",
        "\n",
        "# ============================\n",
        "# Find free port if default is busy\n",
        "# ============================\n",
        "def find_free_port(default_port):\n",
        "    import socket\n",
        "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    try:\n",
        "        s.bind(('', default_port))\n",
        "        s.close()\n",
        "        return default_port\n",
        "    except OSError:\n",
        "        s.close()\n",
        "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        s.bind(('', 0))\n",
        "        port = s.getsockname()[1]\n",
        "        s.close()\n",
        "        return port\n",
        "\n",
        "PORT = find_free_port(DEFAULT_PORT)\n",
        "print(f\"âœ… Using port: {PORT}\")\n",
        "\n",
        "# ============================\n",
        "# Save HTML UI\n",
        "# ============================\n",
        "html_content = \"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><title>Cataract Detection AI</title>\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap\" rel=\"stylesheet\">\n",
        "<style>\n",
        "body { font-family: 'Poppins', sans-serif; margin:0; padding:0; background: linear-gradient(to right, #a8edea, #fed6e3); }\n",
        "header { width:100%; background-color:#27ae60; color:white; display:flex; align-items:center; justify-content:space-between; padding:10px 20px; position:fixed; top:0; left:0; z-index:100; }\n",
        "header h1 { margin:0; font-size:24px; }\n",
        ".container { padding:120px 25px 40px; max-width:650px; margin:0 auto; text-align:center; }\n",
        ".description { color:#555; font-size:16px; margin-bottom:20px; }\n",
        ".btn-container { display:flex; justify-content:space-between; max-width:450px; margin:0 auto 30px auto; gap:20px; }\n",
        ".btn { flex:1; padding:25px 0; border-radius:15px; background:white; color:#27ae60; font-weight:600; font-size:18px; cursor:pointer; box-shadow:0 8px 20px rgba(0,0,0,0.2); transition:transform 0.3s, box-shadow 0.3s; text-align:center; user-select:none; }\n",
        ".btn:hover { transform:scale(1.05); box-shadow:0 12px 25px rgba(0,0,0,0.3); }\n",
        "#analyzeBtn { width:220px; background-color:#27ae60; color:white; border:none; border-radius:15px; padding:15px 0; font-size:18px; margin-top:20px; cursor:pointer; }\n",
        "#analyzeBtn:hover { background-color:#2ecc71; }\n",
        "#output { margin-top:20px; font-size:16px; color:#34495e; min-height:40px; white-space:pre-line; font-weight:bold;}\n",
        "#previewImage, #webcamVideo { max-width:100%; border-radius:12px; margin-top:15px; box-shadow:0 8px 20px rgba(0,0,0,0.2); display:none; }\n",
        "</style></head>\n",
        "<body>\n",
        "<header><h1>Cataract Detection AI</h1></header>\n",
        "<div class=\"container\">\n",
        "  <div class=\"description\">Upload an eye image or use your webcam to check for cataracts.</div>\n",
        "  <div class=\"btn-container\">\n",
        "    <input type=\"file\" id=\"imageUpload\" accept=\"image/*\" style=\"display:none;\">\n",
        "    <div class=\"btn\" id=\"uploadBtn\">Upload Image</div>\n",
        "    <div class=\"btn\" id=\"webcamBtn\">Start Webcam</div>\n",
        "  </div>\n",
        "  <img id=\"previewImage\" src=\"\" alt=\"Image Preview\">\n",
        "  <video id=\"webcamVideo\" autoplay playsinline></video>\n",
        "  <canvas id=\"hiddenCanvas\" style=\"display:none;\"></canvas>\n",
        "  <button id=\"analyzeBtn\">Analyze Image</button>\n",
        "  <div id=\"output\">Ready to analyze.</div>\n",
        "</div>\n",
        "<script>\n",
        "const outputEl = document.getElementById('output');\n",
        "const analyzeBtn = document.getElementById('analyzeBtn');\n",
        "const uploadBtn = document.getElementById('uploadBtn');\n",
        "const webcamBtn = document.getElementById('webcamBtn');\n",
        "const imageUpload = document.getElementById('imageUpload');\n",
        "const previewImageEl = document.getElementById('previewImage');\n",
        "const webcamVideoEl = document.getElementById('webcamVideo');\n",
        "const hiddenCanvas = document.getElementById('hiddenCanvas');\n",
        "let webcamStream = null;\n",
        "\n",
        "uploadBtn.addEventListener('click', () => imageUpload.click());\n",
        "imageUpload.addEventListener('change', (e) => {\n",
        "    if (webcamStream) { webcamStream.getTracks().forEach(t=>t.stop()); webcamStream = null; }\n",
        "    const file = e.target.files[0];\n",
        "    if (file) {\n",
        "        const reader = new FileReader();\n",
        "        reader.onload = function(ev) {\n",
        "            previewImageEl.src = ev.target.result;\n",
        "            previewImageEl.style.display = 'block';\n",
        "            webcamVideoEl.style.display = 'none';\n",
        "            outputEl.textContent = \"Image uploaded. Click 'Analyze Image' to check.\";\n",
        "        }\n",
        "        reader.readAsDataURL(file);\n",
        "    }\n",
        "});\n",
        "\n",
        "webcamBtn.addEventListener('click', async () => {\n",
        "    if (webcamStream) {\n",
        "        webcamStream.getTracks().forEach(track => track.stop());\n",
        "        webcamStream = null;\n",
        "        webcamVideoEl.style.display = 'none';\n",
        "        outputEl.textContent = \"Webcam stopped.\";\n",
        "    } else {\n",
        "        try {\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "            webcamVideoEl.srcObject = stream;\n",
        "            webcamVideoEl.style.display = 'block';\n",
        "            previewImageEl.style.display = 'none';\n",
        "            outputEl.textContent = \"Webcam active. Click 'Analyze Image' to analyze a frame.\";\n",
        "            webcamStream = stream;\n",
        "        } catch (err) {\n",
        "            console.error(\"Webcam access error:\", err);\n",
        "            outputEl.textContent = \"Cannot access webcam.\";\n",
        "        }\n",
        "    }\n",
        "});\n",
        "\n",
        "analyzeBtn.addEventListener('click', async function() {\n",
        "    outputEl.textContent = \"Analyzing...\";\n",
        "    let imgData;\n",
        "    const canvas = hiddenCanvas;\n",
        "    const context = canvas.getContext('2d');\n",
        "    const TARGET_W = 224, TARGET_H = 224;\n",
        "\n",
        "    if (previewImageEl.style.display==='block' && previewImageEl.src) {\n",
        "        canvas.width = TARGET_W;\n",
        "        canvas.height = TARGET_H;\n",
        "        context.drawImage(previewImageEl, 0, 0, canvas.width, canvas.height);\n",
        "        imgData = canvas.toDataURL('image/jpeg');\n",
        "    } else if (webcamVideoEl.style.display==='block' && webcamStream) {\n",
        "        canvas.width = TARGET_W;\n",
        "        canvas.height = TARGET_H;\n",
        "        try {\n",
        "          context.drawImage(webcamVideoEl, 0, 0, canvas.width, canvas.height);\n",
        "          imgData = canvas.toDataURL('image/jpeg');\n",
        "        } catch (err) {\n",
        "          console.error(\"Error capturing frame:\", err);\n",
        "          outputEl.textContent = \"Unable to capture webcam frame.\";\n",
        "          return;\n",
        "        }\n",
        "    } else {\n",
        "        outputEl.textContent = \"Upload an image or start webcam first.\";\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    try {\n",
        "        const resp = await fetch('/analyze', {\n",
        "            method:'POST', headers:{'Content-Type':'application/json'},\n",
        "            body: JSON.stringify({image:imgData})\n",
        "        });\n",
        "        const result = await resp.json();\n",
        "        if(result.message && result.confidence!==undefined)\n",
        "            outputEl.innerHTML = `Result: <strong>${result.message}</strong><br>Confidence: ${Math.round(result.confidence*100)}%`;\n",
        "        else if(result.error) outputEl.textContent = \"Error: \" + (result.error || JSON.stringify(result));\n",
        "        else outputEl.textContent = \"Unexpected response: \"+JSON.stringify(result);\n",
        "    } catch(e) {\n",
        "        console.error(e);\n",
        "        outputEl.textContent = \"Prediction failed: \"+e.message;\n",
        "    }\n",
        "});\n",
        "</script>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "with open(\"index.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_content)\n",
        "\n",
        "# ============================\n",
        "# Load Model\n",
        "# ============================\n",
        "model = None\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    try:\n",
        "        keras_config.enable_unsafe_deserialization()\n",
        "        model = load_model(MODEL_PATH, compile=False)\n",
        "        print(\"âœ… Model loaded successfully from:\", MODEL_PATH)\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Error loading model:\", e)\n",
        "else:\n",
        "    print(\"âš ï¸ Model file not found at\", MODEL_PATH)\n",
        "\n",
        "# ============================\n",
        "# Flask app\n",
        "# ============================\n",
        "app = Flask(__name__, static_folder=\".\", static_url_path=\"/\")\n",
        "CORS(app)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return send_from_directory('.', 'index.html')\n",
        "\n",
        "@app.route(\"/analyze\", methods=[\"POST\"])\n",
        "def analyze():\n",
        "    global model\n",
        "    if model is None:\n",
        "        return jsonify({\"error\":\"Model not loaded\"}), 500\n",
        "    try:\n",
        "        data = request.get_json(force=True)\n",
        "        img_data = data.get(\"image\")\n",
        "        if not img_data:\n",
        "            return jsonify({\"error\":\"No image data\"}), 400\n",
        "\n",
        "        header, encoded = img_data.split(',',1)\n",
        "        img_bytes = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\").resize((224,224))\n",
        "        arr = np.asarray(img).astype(\"float32\")/255.0\n",
        "        arr = np.expand_dims(arr, axis=0)\n",
        "\n",
        "        preds = model.predict(arr, verbose=0)\n",
        "\n",
        "        label, confidence = \"Unknown\", 0.0\n",
        "        preds = np.array(preds)\n",
        "\n",
        "        if preds.ndim == 2 and preds.shape[1] == 1:\n",
        "            pred_val = float(preds[0][0])\n",
        "            label = LABELS[1] if pred_val >= 0.5 else LABELS[0]\n",
        "            confidence = pred_val if pred_val >= 0.5 else (1.0 - pred_val)\n",
        "        elif preds.ndim == 1:\n",
        "            if preds.size == 1:\n",
        "                pred_val = float(preds[0])\n",
        "                label = LABELS[1] if pred_val >= 0.5 else LABELS[0]\n",
        "                confidence = pred_val if pred_val >= 0.5 else (1.0 - pred_val)\n",
        "            else:\n",
        "                idx = int(np.argmax(preds))\n",
        "                label = LABELS[idx] if idx < len(LABELS) else f\"class_{idx}\"\n",
        "                confidence = float(np.max(preds))\n",
        "        elif preds.ndim == 2:\n",
        "            idx = int(np.argmax(preds[0]))\n",
        "            label = LABELS[idx] if idx < len(LABELS) else f\"class_{idx}\"\n",
        "            confidence = float(np.max(preds[0]))\n",
        "        else:\n",
        "            flat = preds.ravel()\n",
        "            idx = int(np.argmax(flat))\n",
        "            label = LABELS[idx] if idx < len(LABELS) else f\"class_{idx}\"\n",
        "            confidence = float(np.max(flat))\n",
        "\n",
        "        return jsonify({\"message\":label, \"confidence\":float(confidence)})\n",
        "    except Exception as e:\n",
        "        print(\"Error in analyze:\", e)\n",
        "        return jsonify({\"error\":\"internal server error\",\"details\":str(e)}),500\n",
        "\n",
        "# ============================\n",
        "# Run Flask in background\n",
        "# ============================\n",
        "def run_app():\n",
        "    app.run(host=\"0.0.0.0\", port=PORT, debug=False, use_reloader=False)\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# ============================\n",
        "# Ngrok tunnel\n",
        "# ============================\n",
        "if not NGROK_AUTHTOKEN or NGROK_AUTHTOKEN.strip()==\"\":\n",
        "    print(\"âš ï¸ NGROK_AUTHTOKEN is empty. Skipping public URL creation.\")\n",
        "else:\n",
        "    try:\n",
        "        ngrok.set_auth_token(NGROK_AUTHTOKEN.strip())\n",
        "        time.sleep(1)\n",
        "        public_url = ngrok.connect(PORT).public_url\n",
        "        print(\"ðŸš€ ngrok public URL:\", public_url)\n",
        "        print(\"Open it in your browser to use the Cataract Detection AI.\")\n",
        "    except Exception as e:\n",
        "        print(\"âŒ ngrok error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e14RK3PCFhz",
        "outputId": "e9fd74b3-9126-4249-cb6e-79158f059cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All ngrok tunnels closed.\n"
          ]
        }
      ],
      "source": [
        "# Kill all ngrok tunnels\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "print(\"âœ… All ngrok tunnels closed.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
